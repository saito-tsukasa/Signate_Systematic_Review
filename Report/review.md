# ＜TF-IDFを使ったモデルについて＞
Ridge回帰が一番良かったのでは？正規化はやはり大事。<br>
LGBMはこの場合は精度が上がらなかった。

# ＜BERTを使ったモデルについて＞
結局、何もしないBERTモデルがスコアが高かった。<br>
K-fold法は5よりも7にしたほうがほぼ全てで高い精度が得られたので、非常に効果的。<br>

暫定評価では、f-beta-scoreが最大のものを選んだほうが精度が良かった。<br>
最終評価ではval_scoreが最小のものを選んだほうが精度が良さそう。<br>

CNNもある程度は有効そうだが、何もしないBERTモデルには今回は及ばなかった。<br>
CNNは最終層のみ使用したモデルのほうが精度が良かった。最終3層を用いたモデルはかえって精度が下がる。<br>
CNNを行う際に付け加えたPoolingはMaxPoolingのほうがいい精度。<br>
MeanPoolingも悪くはなさそうだが、MaxPoolingには及ばなかった。<br>

抽出した最終層ベクトルを使った機械学習モデルは割といい精度？<br>
LGBMが一番良かった。これがスタッキングの効果か？<br>

アンサンブルでは暫定評価はかなり良かったが、最終評価はそれほど伸びなかった。<br>
平均的に精度はいいので、やはり効果的な方法であることは間違いなさそう。
