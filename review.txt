＜TF-IDF＞
Ridge回帰が一番良かったのでは？正規化はやはり大事。
LGBMはこの場合は精度が上がらなかった。

＜BERT＞
結局、何もしないBERTモデルがスコアが高かった。
K-fold法は5よりも7にしたほうがほぼ全てで高い精度が得られたので、非常に効果的。

暫定評価では、f-beta-scoreが最大のものを選んだほうが精度が良かった。
最終評価ではval_scoreが最小のものを選んだほうが精度が良さそう。

CNNもある程度は有効そうだが、何もしないBERTモデルには今回は及ばなかった。
CNNは最終層のみ使用したモデルのほうが精度が良かった。最終3層を用いたモデルはかえって精度が下がる。
CNNを行う際に付け加えたPoolingはMaxPoolingのほうがいい精度。
MeanPoolingも悪くはなさそうだが、MaxPoolingには及ばなかった。

抽出した最終層ベクトルを使った機械学習モデルは割といい精度？
LGBMが一番良かった。これがスタッキングの効果か？

アンサンブルでは暫定評価はかなり良かったが、最終評価はそれほど伸びなかった。
平均的に精度はいいので、やはり効果的な方法であることは間違いなさそう。
