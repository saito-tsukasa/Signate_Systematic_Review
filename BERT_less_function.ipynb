{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 準備"
   ],
   "metadata": {
    "id": "hGcv37G7ZqQB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#GPUを確認\r\n",
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'nvidia-smi' は、内部コマンドまたは外部コマンド、\n",
      "操作可能なプログラムまたはバッチ ファイルとして認識されていません。\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1632185769123,
     "user": {
      "displayName": "齋藤僚",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01961766842830427914"
     },
     "user_tz": -540
    },
    "id": "0rvbxHt12ia5",
    "outputId": "51301ae4-6c70-4b8e-c9b4-4bd1817220ee"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "#GPUに渡すための変数device\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "#transformersをインポート\r\n",
    "!pip install transformers"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (4.9.2)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\stsuk\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import copy\r\n",
    "import seaborn as sns\r\n",
    "import os\r\n",
    "import glob\r\n",
    "import re\r\n",
    "import nltk\r\n",
    "nltk.download('punkt')\r\n",
    "import collections\r\n",
    "import scipy\r\n",
    "import math\r\n",
    "import gc\r\n",
    "import random\r\n",
    "import time\r\n",
    "import datetime\r\n",
    "import torch\r\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoModel, AdamW, get_linear_schedule_with_warmup\r\n",
    "from torch.utils.data import TensorDatase, DataLoader, RandomSampler, SequentialSampler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, fbeta_score\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\stsuk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2269,
     "status": "ok",
     "timestamp": 1632185807499,
     "user": {
      "displayName": "齋藤僚",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01961766842830427914"
     },
     "user_tz": -540
    },
    "id": "aUlk8tu5ZqQD",
    "outputId": "2033ca3b-96d8-4f65-e351-ee9143a83820"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#出力フォルダの指定\r\n",
    "DATA_DIR = \"./\"\r\n",
    "OUTPUT_DIR = \"Output/\"\r\n",
    "LOG_DIR = \"Log/\"\r\n",
    "MODEL_DIR = \"Model/\"\r\n",
    "PROBA_DIR = \"Proba/\"\r\n",
    "TOKEN_DIR = \"Token/\"\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#GoogleDriveのマウント\r\n",
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25857,
     "status": "ok",
     "timestamp": 1632185800094,
     "user": {
      "displayName": "齋藤僚",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01961766842830427914"
     },
     "user_tz": -540
    },
    "id": "pp7r9YnMaKAw",
    "outputId": "8ae09885-9396-42cd-c7a8-873a763f1b8d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#作業ディレクトリの移動\r\n",
    "%cd /content/drive/MyDrive/Colab Notebooks/Signate論文コンペ"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[WinError 3] 指定されたパスが見つかりません。: '/content/drive/MyDrive/Colab Notebooks/Signate論文コンペ'\n",
      "c:\\Users\\stsuk\\Desktop\\Signate_BERT\n"
     ]
    }
   ],
   "metadata": {
    "id": "fYdPSFE3Z9FI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# データの読み込み"
   ],
   "metadata": {
    "id": "hZjlrvGfZqQG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\r\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_data[\"text\"] = train_data[\"title\"] + \" \" + train_data[\"abstract\"].fillna(\"\")\r\n",
    "test_data[\"text\"] = test_data[\"title\"] + \" \" + test_data[\"abstract\"].fillna(\"\")\r\n",
    "train_data = train_data.drop([\"title\",\"abstract\"],axis=1)\r\n",
    "test_data = test_data.drop([\"title\",\"abstract\"],axis=1)"
   ],
   "outputs": [],
   "metadata": {
    "id": "eH7yrWLmZqQH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BERT"
   ],
   "metadata": {
    "id": "ghsfFg5b-_I2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "ad974ddfbaf74c009084cf5c36621b3d",
      "25a86f2aeaf447ab88e2f226e7204fb5",
      "f5304fcbec654fe1b9f60d1e0a8fa8b6",
      "50cff41bacca4df3baa17070e4199d0e",
      "df03c543bde84b12b579775c36b6e968",
      "183c81edd44f4c83aa7ad283c0f0ff60",
      "14a6d2650ca04f27b9fc48c9d4b06f68",
      "2b4c01f47ca745a495440e33c9bd8d33",
      "d8bbc74a3f154eeab3cb64de814080b8",
      "bcc592b075684261bd55750cd4dcc51e",
      "fc8f21a181be4ffba406b31efb26faff",
      "4050e8b70ba4459594bfbdf031c0b538",
      "2365e015462d4f2196935320f27d2c2e",
      "d891d0316d7f479d94129a9b028b2a12",
      "7375bfcdf4624595a82915f09fe387df",
      "a8a7e48cb35245a386554745fc550f8e",
      "f41d8e584c5f47b182f6a94b7af1c868",
      "f23f2508d16e43888192620ff3a521b6",
      "41eeb8d0e0124323bfae10c115ce495f",
      "1763beaf36bc49aea4b5dff9d3806fd1",
      "3d32778724f6458b9478b1d5fd5e1e92",
      "cad2fe0f01d148e3b20bec82c5539fb8"
     ]
    },
    "executionInfo": {
     "elapsed": 3781,
     "status": "ok",
     "timestamp": 1632186002788,
     "user": {
      "displayName": "齋藤僚",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01961766842830427914"
     },
     "user_tz": -540
    },
    "id": "ECcD8dx-ZqQK",
    "outputId": "099487b3-8e71-4269-8c48-170bc5dd94a0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## トークン数チェック"
   ],
   "metadata": {
    "id": "H9EghFCtZqQL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "max_lens_train = []\r\n",
    "i = 0\r\n",
    "for x in train_data[\"text\"]:\r\n",
    "    max_lens_train.append(len(tokenizer.tokenize(x)))\r\n",
    "    max_lens = (len(tokenizer.tokenize(x)))\r\n",
    "    if max_lens >= 256:\r\n",
    "        i += 1     \r\n",
    "        \r\n",
    "max_lens_test = []\r\n",
    "j = 0\r\n",
    "for x in test_data[\"text\"]:\r\n",
    "    max_lens_test.append(len(tokenizer.tokenize(x)))\r\n",
    "    max_lens = (len(tokenizer.tokenize(x)))\r\n",
    "    if max_lens >= 256:\r\n",
    "        j += 1\r\n",
    "\r\n",
    "print(\"最大値：\",max(max_lens_train),\",trainの文字数512オーバーは\",i)\r\n",
    "print(\"最大値：\",max(max_lens_test),\",testの文字数512オーバーは\",j)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "最大値： 33 ,trainの文字数512オーバーは 0\n"
     ]
    }
   ],
   "metadata": {
    "id": "4Dy3gSsWZqQL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERTのモデル学習"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ここでやってること**  \n",
    "・文章をトークンに分ける  \n",
    "・スペシャルトークン[CLS],[SEP]を追加  \n",
    "・トークンに番号を付与  \n",
    "・文章を同じ長さに統一  \n",
    "・実際のトークンと[PAD]トークンを分けるアテンションマスクを作成"
   ],
   "metadata": {
    "id": "YqjByIMkZqQM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "text_list = train_data['text'].tolist()\r\n",
    "\r\n",
    "encoded_dict = tokenizer.batch_encode_plus(\r\n",
    "                                            text_list,\r\n",
    "                                            add_special_tokens = True,      # [CLS]と[SEP]を追加\r\n",
    "                                            max_length = 10,                # 最大トークン数\r\n",
    "                                            pad_to_max_length = True,       # paddingの方法(512に満たない場合は[PAD]を追加）\r\n",
    "                                            return_attention_mask = True,   # attention_mask : 入力トークン(1)とパディングトークン(0)を区別\r\n",
    "                                            return_tensors = 'pt'           # pytorchのテンソル型に渡す\r\n",
    "                                            )\r\n",
    "\r\n",
    "input_ids = encoded_dict.input_ids\r\n",
    "attention_masks = encoded_dict.attention_mask\r\n",
    "labels = torch.Tensor(train_data['judgement'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\stsuk\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2184: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26862,
     "status": "ok",
     "timestamp": 1632186049683,
     "user": {
      "displayName": "齋藤僚",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01961766842830427914"
     },
     "user_tz": -540
    },
    "id": "nI2qOxR_ZqQN",
    "outputId": "a928403b-4a93-4cf4-cea2-1802f45a6d55"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**データの分割を行っている**"
   ],
   "metadata": {
    "id": "urnFCHqEZqQN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# データセットの作成\r\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\r\n",
    "\r\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.3)\r\n",
    "\r\n",
    "print(\"train_dataset Size :\", len(train_dataset))\r\n",
    "print(\"val_dataset Size :\", len(val_dataset))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_dataset Size : 7\n",
      "val_dataset Size : 3\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1632186064105,
     "user": {
      "displayName": "齋藤僚",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01961766842830427914"
     },
     "user_tz": -540
    },
    "id": "KVo5r--CZqQN",
    "outputId": "474c7443-3465-48f1-8a61-39a989775997"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**DataLoaderの作成**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "batch_size = 16\r\n",
    "\r\n",
    "train_dataloader = DataLoader(\r\n",
    "                            train_dataset,                              # The training samples.\r\n",
    "                            sampler = RandomSampler(train_dataset),     # 重複無しでランダムな順番で読み込む\r\n",
    "                            batch_size = batch_size,                    # Trains with this batch size.\r\n",
    "                            drop_last=True                              # batchサイズで割り切れなかった分は切り捨てる\r\n",
    "                            )\r\n",
    "\r\n",
    "validation_dataloader = DataLoader(\r\n",
    "                                    val_dataset,                                # The validation samples.\r\n",
    "                                    sampler = SequentialSampler(val_dataset),   # 重複無しでランダムな順番で読み込む\r\n",
    "                                    batch_size = batch_size)                    # Evaluate with this batch size."
   ],
   "outputs": [],
   "metadata": {
    "id": "6JoL6GopZqQN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**分類モデルの定義**"
   ],
   "metadata": {
    "id": "sKcDbR-LZqQO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\r\n",
    "                                                            \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\r\n",
    "                                                            output_attentions = False,                              # False:attentionは出力しない\r\n",
    "                                                            output_hidden_states = True                             # True:隠れ層を出力\r\n",
    "                                                        )\r\n",
    "model.resize_token_embeddings(len(tokenizer))   #入力トークンのサイズに変更する\r\n",
    "model.cuda()    # GPUに渡す"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(28895, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9d7ba3129c3f4f028b03ebad87ea39e8",
      "8782ba82a16745e091391a22af1fadd9",
      "62de89cc7d6c4c78a991be5940103cf4",
      "36b21ed34a88433f8177532aad85e765",
      "b19d861ee15c43b4a58a29980fd3105f",
      "7d12be1cbf4840838a2f3e07594e1828",
      "2fda59744f824eb1901f77d5d0185640",
      "2ee95a4eb76a4799b22dc103cf964dc2",
      "7ff880a2eabc47b7ac13564b29e1d600",
      "8ac141ac671a48df9a8b695b0e3f4ebc",
      "922af8de17f947daa60fb644a83c638c"
     ]
    },
    "executionInfo": {
     "elapsed": 20407,
     "status": "ok",
     "timestamp": 1632186139297,
     "user": {
      "displayName": "齋藤僚",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01961766842830427914"
     },
     "user_tz": -540
    },
    "id": "w4B0AKLFZqQO",
    "outputId": "98be4511-158d-4e3a-d9bb-febd18009458"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**最適化関数**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "optimizer = AdamW(model.parameters(),   # パラメータ\r\n",
    "                  lr = 1e-5,            # 学習率(デフォルトは1e-3)\r\n",
    "                  eps = 1e-8            # 数値を安定させるため分母に追加する項(デフォルトは1e-8)\r\n",
    "                )"
   ],
   "outputs": [],
   "metadata": {
    "id": "8QlX3ydvZqQO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**スケジュラーの定義**  \n",
    "総ステップごとに学習率を変化させていく"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "epochs = 2\r\n",
    "\r\n",
    "total_steps = len(train_dataloader) * epochs # [トレーニングステップ数] = [ミニバッチ数] × [エポック数]\r\n",
    "\r\n",
    "#ウォームアップ期間が0からオプティマイザーに設定された初期lrまで直線的に増加した後、オプティマイザーに設定された初期lrから0に直線的に減少する学習率でスケジュールを作成\r\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
    "                                            num_warmup_steps = 0,               # ウォームアップフェーズのステップ数\r\n",
    "                                            num_training_steps = total_steps)   #トレーニングステップの総数"
   ],
   "outputs": [],
   "metadata": {
    "id": "tPrMG6heZqQP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**評価関数の定義**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "Threshold = 0.023\r\n",
    "\r\n",
    "def flat_accuracy(logits, labels):\r\n",
    "    pred_flat = np.where(torch.nn.Sigmoid(logits).flatten() < Threshold, 0, 1)\r\n",
    "    labels_flat = labels.flatten()\r\n",
    "    return accuracy_score(pred_flat, labels_flat)\r\n",
    "\r\n",
    "def F_Beta_Score(logits, labels):\r\n",
    "    pred_flat = np.where(torch.nn.Sigmoid(logits).flatten() < Threshold, 0, 1)\r\n",
    "    labels_flat = labels.flatten()\r\n",
    "    return fbeta_score(pred_flat, labels_flat, beta=7)"
   ],
   "outputs": [],
   "metadata": {
    "id": "Yo_ziy7MZqQP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**時間計測**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "def format_time(elapsed):\r\n",
    "    # Round to the nearest second.\r\n",
    "    elapsed_rounded = int(round((elapsed)))\r\n",
    "    \r\n",
    "    # Format as hh:mm:ss\r\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "outputs": [],
   "metadata": {
    "id": "En9ByPFkZqQP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**本番**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "#生成される乱数をあらかじめ指定\r\n",
    "seed_val = 42\r\n",
    "\r\n",
    "random.seed(seed_val)\r\n",
    "np.random.seed(seed_val)\r\n",
    "torch.manual_seed(seed_val)\r\n",
    "torch.cuda.manual_seed_all(seed_val)\r\n",
    "\r\n",
    "logits_list = []\r\n",
    "training_stats = []\r\n",
    "\r\n",
    "# トレーニング時間計測するために現在の時間情報を取得\r\n",
    "total_t0 = time.time()\r\n",
    "\r\n",
    "epochs = 2\r\n",
    "\r\n",
    "for epoch in range(0, epochs):\r\n",
    "    \r\n",
    "    print()\r\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\r\n",
    "    print('Training...')\r\n",
    "\r\n",
    "    t0 = time.time()\r\n",
    "    total_train_loss = 0\r\n",
    "    \r\n",
    "    model.train()\r\n",
    "\r\n",
    "    for step, (input_ids, attention_masks, labels) in enumerate(train_dataloader):\r\n",
    "        \r\n",
    "        if step % 100 == 0 and not step == 0:\r\n",
    "            elapsed = format_time(time.time() - t0)\r\n",
    "\r\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
    "\r\n",
    "        input_ids = input_ids.to(device)               # トークンIDの行列\r\n",
    "        attention_masks = attention_masks.to(device)   # attention_maskの行列\r\n",
    "        labels = labels.to(device)                     # ラベルデータ\r\n",
    "        \r\n",
    "        optimizer.zero_grad()   #最適化対象の全ての勾配を初期化\r\n",
    "\r\n",
    "        outputs = model(input_ids=input_ids, \r\n",
    "                        attention_mask = attention_masks,\r\n",
    "                        token_type_ids=None,\r\n",
    "                        labels=labels)\r\n",
    "        \r\n",
    "        y_proba = torch.nn.Sigmoid(outputs.logits).squeeze()\r\n",
    "        \r\n",
    "        loss = torch.nn.BCELoss(y_proba, labels)    #損失を出力\r\n",
    "        total_train_loss += loss.item()             #損失を合計する\r\n",
    "        loss.backward()                             #勾配(微分)を計算する\r\n",
    "\r\n",
    "        optimizer.step()    # パラメータを更新し、計算された勾配を使ってステップを踏む。オプティマイザは、学習率などに基づいてパラメータをどのように変更するか、「更新ルール」を決定する。　\r\n",
    "                            # 勾配や学習率などに基づいて、パラメータをどのように変更するかを決定します。\r\n",
    "\r\n",
    "    scheduler.step()    # 学習率の更新\r\n",
    "\r\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)  # 全バッチの損失関数の平均を計算\r\n",
    "    \r\n",
    "    # トレーニング時間計測\r\n",
    "    training_time = format_time(time.time() - t0)\r\n",
    "\r\n",
    "    print()\r\n",
    "    print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\r\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\r\n",
    "        \r\n",
    "    # ========================================\r\n",
    "    #               評価\r\n",
    "    # ========================================\r\n",
    "\r\n",
    "    print(\"\")\r\n",
    "    print(\"Running Validation...\")\r\n",
    "\r\n",
    "    t0 = time.time()\r\n",
    "\r\n",
    "    model.eval()  # モデルを評価モードに変更（dropout & batch norm の切り替え）\r\n",
    "\r\n",
    "    total_eval_accuracy = 0\r\n",
    "    total_eval_fbeta_score = 0\r\n",
    "\r\n",
    "    total_eval_loss = 0\r\n",
    "    nb_eval_steps = 0\r\n",
    "\r\n",
    "    for step, (input_ids, attention_masks, labels) in validation_dataloader:\r\n",
    "        \r\n",
    "        input_ids = input_ids.to(device)\r\n",
    "        attention_masks = attention_masks.to(device)\r\n",
    "        labels = labels.to(device)\r\n",
    "        \r\n",
    "        with torch.no_grad():        \r\n",
    "            outputs = model(input_ids, \r\n",
    "                            attention_mask=attention_masks)\r\n",
    "        \r\n",
    "        y_proba = torch.nn.Sigmoid(outputs.logits).squeeze()\r\n",
    "        \r\n",
    "        loss = torch.nn.BCELoss(y_proba, labels)    #損失を出力\r\n",
    "        total_eval_loss += loss.item()              #損失を合計する\r\n",
    "        \r\n",
    "        logits = outputs.logits.detach().cpu().numpy()  # detach:tensor型から勾配情報を抜く cpu():CPUに切り替える\r\n",
    "        labels = labels.to('cpu').numpy()\r\n",
    "\r\n",
    "        #最終エポックのlogitsを保存\r\n",
    "        if epoch_i == epochs-1:\r\n",
    "            logits_list.extend(logits)\r\n",
    "\r\n",
    "        total_eval_accuracy += flat_accuracy(logits, labels)\r\n",
    "        total_eval_fbeta_score += F_Beta_Score(logits, labels)\r\n",
    "\r\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\r\n",
    "    avg_val_fbeta_score = total_eval_fbeta_score / len(validation_dataloader)\r\n",
    "    print(\"  Accuracy: {0:.5f}\".format(avg_val_accuracy))\r\n",
    "    print(\"  f-bata-score: {0:.5f}\".format(avg_val_fbeta_score))\r\n",
    "\r\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\r\n",
    "    validation_time = format_time(time.time() - t0)\r\n",
    "    print(\"  Validation Loss: {0:.5f}\".format(avg_val_loss))\r\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\r\n",
    "\r\n",
    "    training_stats.append(\r\n",
    "                        {\r\n",
    "                        'epoch': epoch + 1,\r\n",
    "                        'Training Loss': avg_train_loss,\r\n",
    "                        'Valid. Loss': avg_val_loss,\r\n",
    "                        'Valid. Accur.': avg_val_accuracy,\r\n",
    "                        'Training Time': training_time,\r\n",
    "                        'Validation Time': validation_time\r\n",
    "                        }\r\n",
    "                        )\r\n",
    "\r\n",
    "print(\"\")\r\n",
    "print(\"Training complete!\")\r\n",
    "\r\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([2])) must be the same as input size (torch.Size([2, 2]))",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-f2c6c3461deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m#モデルに当てはめ、出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         outputs = model(input_ids=input_ids, \n\u001b[0m\u001b[0;32m     52\u001b[0m                         \u001b[0mattention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1558\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multi_label_classification\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1560\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[0;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   2956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2957\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2958\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([2])) must be the same as input size (torch.Size([2, 2]))"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "error",
     "timestamp": 1632186175100,
     "user": {
      "displayName": "齋藤僚",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01961766842830427914"
     },
     "user_tz": -540
    },
    "id": "TKsg5MOgZqQP",
    "outputId": "4a676017-570a-4a2a-a647-9162f3ed3835"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#labelの付与(閾値以下であれば0,そうでなければ1を付与)\r\n",
    "Threshold = 0.023\r\n",
    "pred_flat = np.where(torch.nn.Sigmoid(np.asarray(logits_list)).flatten() < Threshold, 0, 1)"
   ],
   "outputs": [],
   "metadata": {
    "id": "JP2GnaYDLEED"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#confusion matrix\r\n",
    "answer_labels = []\r\n",
    "\r\n",
    "for i in range(len(val_dataset)):\r\n",
    "    answer_labels.append(val_dataset[i][2].to('cpu').numpy())\r\n",
    "\r\n",
    "print(confusion_matrix(np.asarray(answer_labels), pred_flat))"
   ],
   "outputs": [],
   "metadata": {
    "id": "JP-2aMUUrNLw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#fbeta_score\r\n",
    "fbeta_score(np.asarray(answer_labels), pred_flat, beta=7)"
   ],
   "outputs": [],
   "metadata": {
    "id": "VfDsVE59qjQd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 作成したBERTモデルでtestデータを予測"
   ],
   "metadata": {
    "id": "7wjng1cxDBRV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text_list = test_data['text'].tolist()\r\n",
    "\r\n",
    "encoded_dict = tokenizer.batch_encode_plus(\r\n",
    "                                            text_list,\r\n",
    "                                            add_special_tokens = True,      # [CLS]と[SEP]を追加\r\n",
    "                                            max_length = 10,                # 最大トークン数\r\n",
    "                                            pad_to_max_length = True,       # paddingの方法(512に満たない場合は[PAD]を追加）\r\n",
    "                                            return_attention_mask = True,   # attention_mask : 入力トークン(1)とパディングトークン(0)を区別\r\n",
    "                                            return_tensors = 'pt'           # pytorchのテンソル型に渡す\r\n",
    "                                            )\r\n",
    "\r\n",
    "input_ids = encoded_dict.input_ids\r\n",
    "attention_masks = encoded_dict.attention_mask"
   ],
   "outputs": [],
   "metadata": {
    "id": "Gb5m61APDhDl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**データの分割を行っている**"
   ],
   "metadata": {
    "id": "cuFB3zV2DhDm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_dataset = TensorDataset(input_ids, attention_masks)\r\n",
    "\r\n",
    "print('{:>5,} test samples'.format(len(test_dataset)))"
   ],
   "outputs": [],
   "metadata": {
    "id": "5JjbbIQpDhDm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**DataLoaderの作成**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 16   #8以上だと動かない\r\n",
    "\r\n",
    "test_dataloader = DataLoader(\r\n",
    "                            test_dataset,                               # The training samples.\r\n",
    "                            sampler = RandomSampler(train_dataset),     # 重複無しでランダムな順番で読み込む\r\n",
    "                            batch_size = batch_size,                    # Trains with this batch size\r\n",
    "                            shuffle=False\r\n",
    "                            )"
   ],
   "outputs": [],
   "metadata": {
    "id": "WYGHI8LaDhDn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**testデータを学習させる**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#生成される乱数をあらかじめ指定\r\n",
    "seed_val = 42\r\n",
    "\r\n",
    "random.seed(seed_val)\r\n",
    "np.random.seed(seed_val)\r\n",
    "torch.manual_seed(seed_val)\r\n",
    "torch.cuda.manual_seed_all(seed_val)\r\n",
    "\r\n",
    "test_logits_list = []\r\n",
    "\r\n",
    "# ========================================\r\n",
    "#               評価\r\n",
    "# ========================================\r\n",
    "print(\"\")\r\n",
    "print(\"Running Validation...\")\r\n",
    "\r\n",
    "t0 = time.time()\r\n",
    "\r\n",
    "model.eval()  # モデルを評価モードに変更（dropout & batch norm の切り替え）\r\n",
    "\r\n",
    "# Evaluate data for one epoch\r\n",
    "for step, (input_ids, attention_masks) in test_dataloader:\r\n",
    "    \r\n",
    "    input_ids = input_ids.to(device)\r\n",
    "    attention_masks = attention_masks.to(device)\r\n",
    "    \r\n",
    "    with torch.no_grad():        \r\n",
    "        outputs = model(input_ids, \r\n",
    "                        attention_mask=attention_masks)\r\n",
    "\r\n",
    "    logits = outputs.logits # 最後の活性化関数に通す前の値\r\n",
    "\r\n",
    "    test_logits_list.append(logits)"
   ],
   "outputs": [],
   "metadata": {
    "id": "kCY4q1z6DhDp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict = pd.Series(model.predict_proba(test)[:,1]).apply(pred)\r\n",
    "predict.index=range(27145,67979)\r\n",
    "predict.to_csv('submit.csv',header=None)"
   ],
   "outputs": [],
   "metadata": {
    "id": "OGJUjcqpZqQY"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Q2DS_BERT_less_function.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e73f067f1c59be12cfda938665c6a960a5d3ec55ce3a05feea7c329cb1f7e9af"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14a6d2650ca04f27b9fc48c9d4b06f68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1763beaf36bc49aea4b5dff9d3806fd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "183c81edd44f4c83aa7ad283c0f0ff60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2365e015462d4f2196935320f27d2c2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25a86f2aeaf447ab88e2f226e7204fb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b4c01f47ca745a495440e33c9bd8d33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ee95a4eb76a4799b22dc103cf964dc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2fda59744f824eb1901f77d5d0185640": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36b21ed34a88433f8177532aad85e765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ff880a2eabc47b7ac13564b29e1d600",
      "max": 440472042,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ee95a4eb76a4799b22dc103cf964dc2",
      "value": 440472042
     }
    },
    "3d32778724f6458b9478b1d5fd5e1e92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4050e8b70ba4459594bfbdf031c0b538": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d891d0316d7f479d94129a9b028b2a12",
       "IPY_MODEL_7375bfcdf4624595a82915f09fe387df",
       "IPY_MODEL_a8a7e48cb35245a386554745fc550f8e"
      ],
      "layout": "IPY_MODEL_2365e015462d4f2196935320f27d2c2e"
     }
    },
    "41eeb8d0e0124323bfae10c115ce495f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "50cff41bacca4df3baa17070e4199d0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8bbc74a3f154eeab3cb64de814080b8",
      "max": 337,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b4c01f47ca745a495440e33c9bd8d33",
      "value": 337
     }
    },
    "62de89cc7d6c4c78a991be5940103cf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fda59744f824eb1901f77d5d0185640",
      "placeholder": "​",
      "style": "IPY_MODEL_7d12be1cbf4840838a2f3e07594e1828",
      "value": "Downloading: 100%"
     }
    },
    "7375bfcdf4624595a82915f09fe387df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1763beaf36bc49aea4b5dff9d3806fd1",
      "max": 225062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41eeb8d0e0124323bfae10c115ce495f",
      "value": 225062
     }
    },
    "7d12be1cbf4840838a2f3e07594e1828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ff880a2eabc47b7ac13564b29e1d600": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8782ba82a16745e091391a22af1fadd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ac141ac671a48df9a8b695b0e3f4ebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "922af8de17f947daa60fb644a83c638c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d7ba3129c3f4f028b03ebad87ea39e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62de89cc7d6c4c78a991be5940103cf4",
       "IPY_MODEL_36b21ed34a88433f8177532aad85e765",
       "IPY_MODEL_b19d861ee15c43b4a58a29980fd3105f"
      ],
      "layout": "IPY_MODEL_8782ba82a16745e091391a22af1fadd9"
     }
    },
    "a8a7e48cb35245a386554745fc550f8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cad2fe0f01d148e3b20bec82c5539fb8",
      "placeholder": "​",
      "style": "IPY_MODEL_3d32778724f6458b9478b1d5fd5e1e92",
      "value": " 225k/225k [00:00&lt;00:00, 626kB/s]"
     }
    },
    "ad974ddfbaf74c009084cf5c36621b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5304fcbec654fe1b9f60d1e0a8fa8b6",
       "IPY_MODEL_50cff41bacca4df3baa17070e4199d0e",
       "IPY_MODEL_df03c543bde84b12b579775c36b6e968"
      ],
      "layout": "IPY_MODEL_25a86f2aeaf447ab88e2f226e7204fb5"
     }
    },
    "b19d861ee15c43b4a58a29980fd3105f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_922af8de17f947daa60fb644a83c638c",
      "placeholder": "​",
      "style": "IPY_MODEL_8ac141ac671a48df9a8b695b0e3f4ebc",
      "value": " 440M/440M [00:10&lt;00:00, 42.6MB/s]"
     }
    },
    "bcc592b075684261bd55750cd4dcc51e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cad2fe0f01d148e3b20bec82c5539fb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d891d0316d7f479d94129a9b028b2a12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f23f2508d16e43888192620ff3a521b6",
      "placeholder": "​",
      "style": "IPY_MODEL_f41d8e584c5f47b182f6a94b7af1c868",
      "value": "Downloading: 100%"
     }
    },
    "d8bbc74a3f154eeab3cb64de814080b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df03c543bde84b12b579775c36b6e968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc8f21a181be4ffba406b31efb26faff",
      "placeholder": "​",
      "style": "IPY_MODEL_bcc592b075684261bd55750cd4dcc51e",
      "value": " 337/337 [00:00&lt;00:00, 10.3kB/s]"
     }
    },
    "f23f2508d16e43888192620ff3a521b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f41d8e584c5f47b182f6a94b7af1c868": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5304fcbec654fe1b9f60d1e0a8fa8b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14a6d2650ca04f27b9fc48c9d4b06f68",
      "placeholder": "​",
      "style": "IPY_MODEL_183c81edd44f4c83aa7ad283c0f0ff60",
      "value": "Downloading: 100%"
     }
    },
    "fc8f21a181be4ffba406b31efb26faff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}