{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":4,"language_info":{"name":"python","version":"3.9.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit"},"interpreter":{"hash":"ed82b2b74e68bccf28c13ad9836498e9e13ea4ffc3fa6533ceea69e550a3c9a6"},"colab":{"name":"Baseline.ipynb","provenance":[{"file_id":"10WC8El4yYQF3yWWL1plsoWUJW3gVDIX9","timestamp":1630634512028},{"file_id":"https://github.com/Go-horino/Q2DS_Signate_compettion/blob/horino/Q2DS_BERT_Pub.ipynb","timestamp":1629613662275}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eBchDCgszNBc"},"source":["# 準備"]},{"cell_type":"code","metadata":{"id":"6LOOlQ2mkafU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633923059239,"user_tz":-540,"elapsed":671,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"c768e028-5427-4fbe-c62f-74c236f7d670"},"source":["!nvidia-smi\n","# 16280MiBじゃなかったら16epochで動かないので文字数を512から減らす処理が必要"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Oct 11 03:30:58 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"_gLp2ys-irYI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633923062737,"user_tz":-540,"elapsed":2843,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"b18b66ba-1135-48f0-eab6-7a604c5b1466"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"]}]},{"cell_type":"code","metadata":{"id":"lq0foJoCin1R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633923065455,"user_tz":-540,"elapsed":2723,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"bf6122c4-6aea-45e7-d424-49c06dd35def"},"source":["import os\n","import sys\n","import math\n","from math import exp\n","import random\n","import time\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import lr_scheduler\n","from transformers import AutoTokenizer,AutoModel,AutoModelForSequenceClassification,AdamW\n","from sklearn.metrics import fbeta_score\n","from sklearn.model_selection import StratifiedKFold\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm.notebook import tqdm\n","from scipy.optimize import minimize, minimize_scalar\n","\n","import nltk\n","nltk.download(\"punkt\")\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords \n","\n","import re"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"0OmfGIGMin1T","executionInfo":{"status":"ok","timestamp":1633923065457,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["DATA_DIR = \"Data/\"\n","OUTPUT_DIR = \"Output/\"\n","LOG_DIR = \"log/\"\n","MODEL_DIR = \"Model/\"\n","Proba_DIR = 'Proba/'\n","warnings.filterwarnings(\"ignore\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCTTXavji8pO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633923065458,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"55207f27-cce6-4547-fe62-8300107c5847"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CO1Vr8ODU5wM","executionInfo":{"status":"ok","timestamp":1633923065458,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"6d8afe1b-4f62-4b05-bc91-75d14f14e177"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/Signate論文コンペ"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Signate論文コンペ\n"]}]},{"cell_type":"code","metadata":{"id":"11R8hvLFin1U","executionInfo":{"status":"ok","timestamp":1633923065458,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def init_logger(log_file=LOG_DIR + \"BERT.log\"):\n","    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n","\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = init_logger()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySOFGM5Yin1V","executionInfo":{"status":"ok","timestamp":1633923065458,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def seed_torch(seed = 42):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed = 471\n","seed_torch(seed)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"syrqeO-win1X"},"source":["# データ処理関数の定義"]},{"cell_type":"code","metadata":{"id":"gbaqGhxCzf5o","executionInfo":{"status":"ok","timestamp":1633923065459,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def get_train_data(train):\n","    # 交差検証用の番号を振ります。\n","    Fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n","    for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"judgement\"])):\n","        train.loc[val_index, \"fold\"] = int(n)\n","    train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n","\n","    return train"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaG5XzzBzlgX","executionInfo":{"status":"ok","timestamp":1633923065459,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def covid(text):\n","  text = str.lower(text)\n","  text = text.replace(\"covid-19\", \"coronavirus\")\n","  text = text.replace(\"covid19\", \"coronavirus\")\n","  text = text.replace(\"covi19\", \"coronavirus\")\n","  text = text.replace(\"sars-cov-2\", \"coronavirus\")\n","  text = text.replace(\"covid\", \"coronavirus\")\n","  text = text.replace(\"rt-pcr\", \"pcr\")\n","  text = text.replace(\"rt-qpcr\", \"pcr\")\n","  text = text.replace(\"jc virus\", \"polyomavirus\")\n","  text = text.replace(\"c virus\", \"herpesvirus\")\n","\n","  return text"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"POe843I3zyqS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633923065459,"user_tz":-540,"elapsed":12,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"cf978efb-3aeb-4231-dc89-d144846fce2e"},"source":["import nltk\n","from nltk.corpus import stopwords \n","nltk.download(\"stopwords\")\n","nltk_stopwords=stopwords.words(\"english\")"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"id":"XsV-CjFAin1Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633923065459,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"53ab9508-da44-4a9c-dc78-85b2afe552c4"},"source":["nltk.download(\"stopwords\")\n","nltk_stopwords = stopwords.words(\"english\")\n","\n","def stopword(text):\n","  # 不要な文字の削除\n","  text = re.findall('\\W|\\w+', text)\n","  text = ' '.join(text)\n","  text = text.replace('  ', ' ')\n","  text = re.sub(r\"[0-9]\", \"\",text)\n","  text = word_tokenize(text)\n","\n","  stop_words = nltk_stopwords + [\"(\",\")\",\">\", \"<\",\"*\", \":\", \";\",\"\\\\\", \"_\", \"%\",\"Copyright\",\".\",\"\\\"\",\"'\", \"=\", \"?\",\"!\",\"a\",\"l\",\",\",\"-\",\"@\",\"&\",\"^\",\"/\",\"%\",\"[\",\"]\"]\n","  text = [t for t in text if t not in stop_words]\n","  text=\" \".join(text)\n","\n","  return text\n","  \n","\n","def New_sep(text):\n","  # 文末のカンマのみをNEW_SEPに変えます\n","  text = text.replace(\". \",\"[NEW_SEP]\")\n","  \n","  return text\n","\n","\n","def New_sep_2(text):\n","  # 見栄えをよくします\n","  text = text.replace(\"new_sep\",\"[NEW_SEP]\")\n","\n","  return text"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"-nQWjv3SHbEq"},"source":["### 前処理を少し詳しく\n","まず最初にNew_sep関数で文末のカンマのみを変更します。（数字間のピリオドなどを認識させないため）  \n","次に通常の前処理を行うと\"[NEW_SEP]\"がnew_sepになっています。  \n","最後にnew_sepを元に戻すNew_sep_2を行います。"]},{"cell_type":"markdown","metadata":{"id":"YwxeTiC-in1V"},"source":["# データの読み込み"]},{"cell_type":"code","metadata":{"id":"Ngozx1MVAhpZ","executionInfo":{"status":"ok","timestamp":1633923067477,"user_tz":-540,"elapsed":2026,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["train_data = pd.read_csv(DATA_DIR+'train.csv', encoding='utf8')\n","test_data = pd.read_csv(DATA_DIR+'test.csv', encoding='utf8')\n","\n","train_data['text'] = train_data['title'] + ' ' + train_data['abstract'].fillna('')\n","test_data['text'] = test_data['title'] + ' ' + test_data['abstract'].fillna('')\n","\n","train = train_data.drop(columns=['title', 'abstract'])\n","test = test_data.drop(columns=['title', 'abstract'])\n","\n","sub = pd.read_csv(DATA_DIR+\"sample_submit.csv\", header=None)\n","sub.columns = [\"id\",\"judgement\"]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"xcxzliWABMeB","executionInfo":{"status":"ok","timestamp":1633923067482,"user_tz":-540,"elapsed":26,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["# foldを振り分ける\n","train=get_train_data(train)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6rYhPPJ-6-e","executionInfo":{"status":"ok","timestamp":1633923067483,"user_tz":-540,"elapsed":24,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"b2487d89-6473-4e74-8608-5e9cacbff4f0"},"source":["train['fold'].value_counts().sort_index()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    5429\n","1    5429\n","2    5429\n","3    5429\n","4    5429\n","Name: fold, dtype: int64"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"Bs2pCuqaiCA3"},"source":["## BERTの種類\n","- SciBert … 科学論文に特化した単語で学習したBERTモデル 評価指標無し  \n","\"allenai/scibert_scivocab_uncased\"\n","- PubmedBert … Microsoftが作成した、生物医学論文のテキストを学習したBERTモデル 最高精度- LB:0.9114,CV 0.898 \n"," \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n","- COVID-SciBert … SciBertをベースにコロナウイルスの医学論文テキストを学習させたBERTモデル 評価指標無し　  \n","\"lordtt13/COVID-SciBERT\"\n","-BioELECTRA…生物医学領域、Pubmedで事前学習している  \n","\"kamalkraj/bioelectra-base-discriminator-pubmed\""]},{"cell_type":"markdown","metadata":{"id":"lRHCR2Myl5_q"},"source":["# インプットする文字の長さ測定"]},{"cell_type":"code","metadata":{"id":"v7ewM5MJmDdf","executionInfo":{"status":"ok","timestamp":1633923067483,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["# train_data[\"text\"] = train_data[\"text\"].apply(New_sep)\n","# test_data[\"text\"] = test_data[\"text\"].apply(New_sep)\n","# train_data[\"text\"] = train_data[\"text\"].apply(covid)\n","# test_data[\"text\"] = test_data[\"text\"].apply(covid)\n","# train_data[\"text\"] = train_data[\"text\"].apply(stopword)\n","# test_data[\"text\"] = test_data[\"text\"].apply(stopword)\n","# train_data[\"text\"] = train_data[\"text\"].apply(New_sep_2)\n","# test_data[\"text\"] = test_data[\"text\"].apply(New_sep_2)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnB14a4l2hdq","executionInfo":{"status":"ok","timestamp":1633923067483,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["#tokenを調べて出力したい\n","#tokenizer=AutoTokenizer.from_pretrained(\"kamalkraj/bioelectra-base-discriminator-pubmed\")\n","#tokenizer.add_tokens([\"[NEW_SEP]\"], special_tokens=True)\n","\n","#tokenリストを出力\n","#pd.DataFrame(tokenizer.vocab.keys(), columns=['token']).to_csv('Token/'+'kamalkraj_bioelectra-base-discriminator-pubmed_token_list.csv')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"1P9hEj7BnAQf","executionInfo":{"status":"ok","timestamp":1633923067483,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["# max_lens_train=[]\n","# i=0\n","# j=0\n","# max_len=512 # 任意に設定\n","\n","# for x in train_data[\"text\"]:\n","#     max_lens_train.append(len(tokenizer.tokenize(x)))\n","#     max_lens=(len(tokenizer.tokenize(x)))\n","#     if max_lens >=max_len:\n","#         i+=1        \n","# max_lens_test=[]\n","# for x in test_data[\"text\"]:\n","#     max_lens_test.append(len(tokenizer.tokenize(x)))\n","#     max_lens=(len(tokenizer.tokenize(x)))\n","#     if max_lens >=max_len:\n","#         j+=1\n","# print(\"トークンの最大値：{},trainの文字数{}オーバーは{}個です\".format(max(max_lens_train),max_len,i))\n","# print(\"トークンの最大値：{},testの文字数{}オーバーは{}個です\".format(max(max_lens_test),max_len,j))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKK78WwrHv4r","executionInfo":{"status":"ok","timestamp":1633923067484,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["# # 分布を出力\n","# fig,(ax1,ax2)=plt.subplots(2,1,figsize=(15,7))\n","\n","# sns.histplot(max_lens_train, ax = ax1, label = \"train\")\n","# ax1.legend(loc=\"lower right\",fontsize=30)\n","# ax1.set_xlabel(xlabel=\"lens\")\n","# ax1.grid()\n","# ax1.set_title(\"train\",fontsize=10)\n","# ax1.set_xlim(1,800)\n","# ax1.legend(loc='upper right',fontsize=10)\n","\n","# sns.histplot(max_lens_test, ax = ax2, label = \"test\")\n","# ax2.legend(loc=\"lower right\",fontsize=20)\n","# ax2.set_xlabel(xlabel=\"lens\")\n","# ax2.grid()\n","# ax2.set_title(\"train\",fontsize=10)\n","# ax2.set_xlim(1,800)\n","# ax2.legend(loc='upper right',fontsize=10)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KRGeLAyV61C3"},"source":["# BERTに使う関数・クラスの定義"]},{"cell_type":"markdown","metadata":{"id":"-_Wp6KSbin1a"},"source":["## データセット定義"]},{"cell_type":"code","metadata":{"id":"FcHzuUJgin1a","executionInfo":{"status":"ok","timestamp":1633923067485,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["class BaseDataset(Dataset):\n","    def __init__(self, df, model_name, include_labels=True):\n","        tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        tokenizer.add_tokens([\"[NEW_SEP]\"], special_tokens=True)\n","        self.df = df\n","        self.include_labels = include_labels\n","        df[\"text\"] = df[\"text\"].apply(New_sep)\n","        df[\"text\"] = df[\"text\"].apply(covid)\n","        df[\"text\"] = df[\"text\"].apply(stopword)\n","        df[\"text\"] = df[\"text\"].apply(New_sep_2)\n","        self.text = df[\"text\"].tolist()\n","        self.encoded = tokenizer.batch_encode_plus(\n","            self.text,\n","            padding = \"max_length\",            \n","            max_length = 512,\n","            truncation = True,\n","            return_attention_mask = True,\n","            return_tensors = \"pt\"\n","        )\n","        if self.include_labels:\n","            self.labels = df[\"judgement\"].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        input_ids = torch.tensor(self.encoded['input_ids'][idx])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][idx])\n","\n","        if self.include_labels:\n","            label = torch.tensor(self.labels[idx]).float()\n","            return input_ids, attention_mask, label\n","\n","        return input_ids, attention_mask"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"abgsgPWxin1a"},"source":["## モデル定義"]},{"cell_type":"code","metadata":{"id":"oNCfxz-61gkR","executionInfo":{"status":"ok","timestamp":1633923067485,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["class BaseModel(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        tokenizer.add_tokens([\"[NEW_SEP]\"], special_tokens=True)\n","        self.model = AutoModelForSequenceClassification.from_pretrained(model_name,\n","                                                                        num_labels = 1,\n","                                                                        output_hidden_states = True)\n","        self.model.resize_token_embeddings(len(tokenizer))\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.model(input_ids=input_ids,\n","                             attention_mask=attention_mask)        \n","        outputs = outputs.logits  \n","\n","        return outputs"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MhJxzqS-in1b"},"source":["## ツール"]},{"cell_type":"code","metadata":{"id":"aIuHFzJNin1b","executionInfo":{"status":"ok","timestamp":1633923067485,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vb8RXrp--YXm","executionInfo":{"status":"ok","timestamp":1633923067486,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def bestFbeta(labels,preds):\n","  # bestFbetaとThresholdを抽出\n","  Threshold_list = []\n","  fbeta_score_list = []\n","  for i in range(1000):\n","      Threshold = i*0.0001\n","      predictions = np.where(preds < Threshold, 0, 1)\n","      Threshold_list.append(Threshold)\n","      fbeta_score_list.append(fbeta_score(labels, predictions, beta=7.0))\n","  for i,j in zip(Threshold_list, fbeta_score_list):\n","    if j == max(fbeta_score_list):\n","      return i,j\n","      break"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wdc06EyJin1c"},"source":["## 学習補助関数"]},{"cell_type":"code","metadata":{"id":"YaO4iGS5in1c","executionInfo":{"status":"ok","timestamp":1633923067486,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def train_fn(train_loader, model, criterion, optimizer, epoch, device):\n","    start = end = time.time()\n","    losses = AverageMeter()\n","    sigmoid = nn.Sigmoid()\n","\n","    # switch to train mode\n","    model.train()\n","\n","    for step, (input_ids, attention_mask, labels) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        \n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        outputs = model(input_ids, attention_mask)\n","\n","        y_preds = sigmoid(outputs).squeeze()\n","\n","        loss = criterion(y_preds, labels)\n","        # record loss\n","        losses.update(loss.item(), batch_size)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        # ミニバッチ学習を128に変更する\n","        #if (step+1)%128==0:\n","        #  optimizer.step()\n","        #  optimizer.zero_grad()\n","\n","\n","        if step % 100 == 0 or step == (len(train_loader) - 1):\n","            print(\n","                f\"Epoch: [{epoch + 1}][{step}/{len(train_loader)-1}] \"\n","                f\"Elapsed {timeSince(start, float(step + 1) / len(train_loader)):s} \"\n","                f\"Loss: {losses.avg:.4f} \"\n","            )      \n","\n","    return losses.avg"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KZF1TUdgin1c"},"source":["## 検証補助関数"]},{"cell_type":"code","metadata":{"id":"GziOvyHKin1d","executionInfo":{"status":"ok","timestamp":1633923067486,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def valid_fn(valid_loader, model, criterion, device):\n","    start = end = time.time()\n","    losses = AverageMeter()\n","    sigmoid = nn.Sigmoid()\n","\n","    # switch to evaluation mode\n","    model.eval()\n","    preds = []\n","\n","    for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        # compute loss\n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask)\n","\n","        y_preds = sigmoid(outputs).squeeze()\n","\n","        if y_preds.size()==torch.Size([]):\n","          y_preds = y_preds.unsqueeze(-1)\n","\n","        loss = criterion(y_preds, labels)\n","        losses.update(loss.item(), batch_size)\n","\n","        # record score\n","        preds.append(y_preds.to(\"cpu\").numpy())\n","\n","        if step % 100 == 0 or step == (len(valid_loader) - 1):\n","            print(\n","                f\"EVAL: [{step}/{len(valid_loader)-1}] \"\n","                f\"Elapsed {timeSince(start, float(step + 1) / len(valid_loader)):s} \"\n","                f\"Loss: {losses.avg:.4f} \"\n","            )\n","\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5U9WITFzin1d"},"source":["## 推論関数"]},{"cell_type":"code","metadata":{"id":"2ixa8Tkrin1d","executionInfo":{"status":"ok","timestamp":1633923067486,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def inference():\n","    model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n","    predictions = []\n","\n","    test_dataset = BaseDataset(test, model_name, include_labels=False)\n","    test_loader = DataLoader(test_dataset,\n","                             batch_size=16,\n","                             shuffle=False,\n","                             num_workers=4,\n","                             pin_memory=True)\n","    sigmoid = nn.Sigmoid()\n","\n","    for fold in range(5):\n","        LOGGER.info(f\"========== model {fold} inference ==========\")\n","        model = BaseModel(model_name)\n","        model.to(device)\n","        model.load_state_dict(torch.load(MODEL_DIR + f\"Pubmed_fold{fold}.pth\")[\"model\"])\n","        model.eval()\n","        preds = []\n","\n","        for i, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total=len(test_loader)):\n","          input_ids = input_ids.to(device)\n","          attention_mask = attention_mask.to(device)\n","          with torch.no_grad():\n","              outputs = model(input_ids, attention_mask)\n","          y_preds = sigmoid(outputs).squeeze()\n","          preds.append(y_preds.to(\"cpu\").numpy())\n","\n","        preds = np.concatenate(preds)\n","        predictions.append(preds)\n","    predictions = np.mean(predictions, axis=0)\n","\n","    return predictions"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RvPvBYKAin1e"},"source":["## 学習関数"]},{"cell_type":"code","metadata":{"id":"s37i0rlzin1e","executionInfo":{"status":"ok","timestamp":1633923067486,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def train_loop(train, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","    model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n","    batch = 16\n","    # ====================================================\n","    # Data Loader\n","    # ====================================================\n","    trn_idx = train[train[\"fold\"] != fold].index\n","    val_idx = train[train[\"fold\"] == fold].index\n","\n","    train_folds = train.loc[trn_idx].reset_index(drop=True)\n","    valid_folds = train.loc[val_idx].reset_index(drop=True)\n","\n","    train_dataset = BaseDataset(train_folds, model_name)\n","    valid_dataset = BaseDataset(valid_folds, model_name)\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch,\n","        shuffle=True,\n","        num_workers=4,\n","        pin_memory=True,\n","        drop_last=True,\n","    )\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=batch,\n","        shuffle=False,\n","        num_workers=4,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # ====================================================\n","    # Model\n","    # ====================================================\n","    model = BaseModel(model_name)\n","    model.to(device)\n","    criterion = nn.BCELoss()\n","\n","    # ====================================================\n","    # Loop\n","    # ====================================================\n","    best_val_loss = 1\n","    best_loss = np.inf\n","    best_score = 0\n","    epochs = 3\n","    LR = 2e-5\n","    # LR = [2e-4, 2e-5, 2e-6]\n","\n","    optimizer = AdamW(model.parameters(), lr=LR)\n","\n","    #scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=1, eta_min=0, last_epoch=-1, verbose=False)\n","\n","    for epoch in range(epochs):\n","        #optimizer = AdamW(model.parameters(), lr=LR[epoch])\n","        start_time = time.time()\n","        # train\n","        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, device)\n","\n","        # eval\n","        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n","        valid_labels = valid_folds[\"judgement\"].values\n","\n","        # scoring\n","        bestThr,score = bestFbeta(valid_labels, preds)\n","\n","        elapsed = time.time() - start_time\n","        LOGGER.info(\n","            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n","        )\n","        LOGGER.info(f\"Epoch {epoch+1} - Score: {score} - Threshold:{bestThr:.4f} - val_loss{avg_val_loss:.4f}\")\n","\n","        if best_score < score:  # or (if avg_val_loss < best_val_loss:)\n","            best_score = score\n","            best_val_loss = avg_val_loss\n","            best_Threshold = bestThr \n","            LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model - bestThr{best_Threshold:.5f} - val_loss{best_val_loss:.4f}\")\n","            torch.save(\n","                {\"model\": model.state_dict(), \"preds\": preds, \"Threshold\":best_Threshold}, MODEL_DIR + f\"Pubmed_fold{fold}.pth\"\n","            )\n","\n","        #scheduler.step()\n","\n","    check_point = torch.load(MODEL_DIR + f\"Pubmed_fold{fold}.pth\")\n","\n","    valid_folds[\"preds\"] = check_point[\"preds\"]\n","    LOGGER.info(f\"Bacthsize :{batch} - LearningRate :{LR}\")\n","    return valid_folds, best_Threshold"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"SoXW2r_iin1e","executionInfo":{"status":"ok","timestamp":1633923067487,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def get_result(result_df,best_threshold):\n","    preds = result_df[\"preds\"].values\n","    labels = result_df[\"judgement\"].values\n","    score = fbeta_score(labels, preds >= best_threshold, beta=7)\n","    LOGGER.info(f\"Score: {score:<.5f} - Threshold：{best_threshold:<.5f}\")"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4K3YhP0in1f"},"source":["## メイン（モデルのトレーニング〜testデータの予測）を行う関数"]},{"cell_type":"code","metadata":{"id":"LI3chxf9in1f","executionInfo":{"status":"ok","timestamp":1633923067487,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def main():\n","    # Training\n","    LOGGER.info(\"BERT PubMed Abstract\")\n","    oof_df = pd.DataFrame()\n","    Threshold_list=[]\n","    for fold in range(5):\n","        _oof_df, best_Threshold = train_loop(train, fold)\n","        oof_df = pd.concat([oof_df, _oof_df])\n","        LOGGER.info(f\"========== fold: {fold} result ==========\")\n","        get_result(_oof_df,best_Threshold)\n","        Threshold_list.append(best_Threshold)\n","        Threshold_mean = np.mean(Threshold_list)\n","    # CV result\n","    LOGGER.info(f\"========== CV ==========\")\n","    get_result(oof_df,Threshold_mean)\n","    \n","    # Save OOF result\n","    oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)\n","\n","    # Inference\n","    predictions_sigmoid = inference()\n","    predictions = np.where(predictions_sigmoid < Threshold_mean, 0, 1)\n","    \n","\n","    # submission\n","    sub[\"judgement\"] = predictions\n","    sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)\n","    LOGGER.info(\"==========CONPLETE==========\")\n","    return predictions_sigmoid, predictions"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iw16swXjB7YW"},"source":["## モデルのトレーニングのみを行う関数"]},{"cell_type":"code","metadata":{"id":"LsWFmQ3f494T","executionInfo":{"status":"ok","timestamp":1633923067487,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def trainning():\n","    # Training\n","    LOGGER.info(\"BERT PubMed Abstract\")\n","    oof_df = pd.DataFrame()\n","    Threshold_list=[]\n","    for fold in range(5):\n","        _oof_df, best_Threshold = train_loop(train, fold)\n","        oof_df = pd.concat([oof_df, _oof_df])\n","        LOGGER.info(f\"========== fold: {fold} result ==========\")\n","        get_result(_oof_df,best_Threshold)\n","        Threshold_list.append(best_Threshold)\n","        Threshold_mean = np.mean(Threshold_list)\n","    # CV result\n","    LOGGER.info(f\"========== CV ==========\")\n","    get_result(oof_df,Threshold_mean)\n","    \n","    # Save OOF result\n","    oof_df.to_csv(OUTPUT_DIR + \"oof_df.csv\", index=False)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"She6dRfLCC8R"},"source":["## testデータの予測を行う関数"]},{"cell_type":"code","metadata":{"id":"TiDn3FD_6o7M","executionInfo":{"status":"ok","timestamp":1633923067487,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["def inference_submit():\n","  # Inference\n","  predictions_sigmoid = inference()\n","  return predictions_sigmoid"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ErXJlW2sCMmH"},"source":["# 実行"]},{"cell_type":"markdown","metadata":{"id":"LiSR9xdR7I0N"},"source":["## mainを実行（モデルのトレーニング〜testデータの予測）"]},{"cell_type":"code","metadata":{"id":"H8k-WWsYin1f","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1633945982652,"user_tz":-540,"elapsed":22915180,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"b10a508d-5623-4d02-867c-2a4b5d9eda9a"},"source":["if __name__ == \"__main__\":\n","    predictions_sigmoid,predictions = main()\n","\n","#確率をファイルとして残す\n","pd.DataFrame(predictions_sigmoid, columns=['proba']).to_csv(Proba_DIR+'proba.csv')"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["BERT PubMed Abstract\n","========== fold: 0 training ==========\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff8d5dbb3a744b1b82163de31e5d3d80","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1356] Elapsed 0m 1s (remain 25m 20s) Loss: 0.6494 \n","Epoch: [1][100/1356] Elapsed 1m 25s (remain 17m 38s) Loss: 0.1371 \n","Epoch: [1][200/1356] Elapsed 2m 49s (remain 16m 12s) Loss: 0.1110 \n","Epoch: [1][300/1356] Elapsed 4m 13s (remain 14m 47s) Loss: 0.1011 \n","Epoch: [1][400/1356] Elapsed 5m 36s (remain 13m 23s) Loss: 0.0920 \n","Epoch: [1][500/1356] Elapsed 7m 0s (remain 11m 59s) Loss: 0.0862 \n","Epoch: [1][600/1356] Elapsed 8m 24s (remain 10m 35s) Loss: 0.0828 \n","Epoch: [1][700/1356] Elapsed 9m 48s (remain 9m 11s) Loss: 0.0779 \n","Epoch: [1][800/1356] Elapsed 11m 13s (remain 7m 47s) Loss: 0.0723 \n","Epoch: [1][900/1356] Elapsed 12m 37s (remain 6m 23s) Loss: 0.0721 \n","Epoch: [1][1000/1356] Elapsed 14m 1s (remain 4m 59s) Loss: 0.0693 \n","Epoch: [1][1100/1356] Elapsed 15m 25s (remain 3m 35s) Loss: 0.0679 \n","Epoch: [1][1200/1356] Elapsed 16m 49s (remain 2m 11s) Loss: 0.0664 \n","Epoch: [1][1300/1356] Elapsed 18m 13s (remain 0m 47s) Loss: 0.0643 \n","Epoch: [1][1356/1356] Elapsed 19m 0s (remain 0m 0s) Loss: 0.0630 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 39s) Loss: 0.0180 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0386 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0466 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0464 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0474 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0630  avg_val_loss: 0.0474  time: 1239s\n","Epoch 1 - Score: 0.9168157423971377 - Threshold:0.0527 - val_loss0.0474\n","Epoch 1 - Save Best Score: 0.9168 Model - bestThr0.05270 - val_loss0.0474\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1356] Elapsed 0m 1s (remain 23m 43s) Loss: 0.0165 \n","Epoch: [2][100/1356] Elapsed 1m 25s (remain 17m 38s) Loss: 0.0222 \n","Epoch: [2][200/1356] Elapsed 2m 49s (remain 16m 13s) Loss: 0.0273 \n","Epoch: [2][300/1356] Elapsed 4m 13s (remain 14m 49s) Loss: 0.0301 \n","Epoch: [2][400/1356] Elapsed 5m 37s (remain 13m 24s) Loss: 0.0301 \n","Epoch: [2][500/1356] Elapsed 7m 1s (remain 12m 0s) Loss: 0.0304 \n","Epoch: [2][600/1356] Elapsed 8m 25s (remain 10m 36s) Loss: 0.0302 \n","Epoch: [2][700/1356] Elapsed 9m 49s (remain 9m 12s) Loss: 0.0326 \n","Epoch: [2][800/1356] Elapsed 11m 14s (remain 7m 47s) Loss: 0.0319 \n","Epoch: [2][900/1356] Elapsed 12m 38s (remain 6m 23s) Loss: 0.0332 \n","Epoch: [2][1000/1356] Elapsed 14m 2s (remain 4m 59s) Loss: 0.0322 \n","Epoch: [2][1100/1356] Elapsed 15m 26s (remain 3m 35s) Loss: 0.0332 \n","Epoch: [2][1200/1356] Elapsed 16m 50s (remain 2m 11s) Loss: 0.0333 \n","Epoch: [2][1300/1356] Elapsed 18m 14s (remain 0m 47s) Loss: 0.0324 \n","Epoch: [2][1356/1356] Elapsed 19m 2s (remain 0m 0s) Loss: 0.0335 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 38s) Loss: 0.0056 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0363 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0426 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0428 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0422 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0335  avg_val_loss: 0.0422  time: 1241s\n","Epoch 2 - Score: 0.9078425389075374 - Threshold:0.0799 - val_loss0.0422\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1356] Elapsed 0m 1s (remain 23m 25s) Loss: 0.0302 \n","Epoch: [3][100/1356] Elapsed 1m 25s (remain 17m 40s) Loss: 0.0174 \n","Epoch: [3][200/1356] Elapsed 2m 49s (remain 16m 14s) Loss: 0.0183 \n","Epoch: [3][300/1356] Elapsed 4m 13s (remain 14m 50s) Loss: 0.0174 \n","Epoch: [3][400/1356] Elapsed 5m 37s (remain 13m 25s) Loss: 0.0173 \n","Epoch: [3][500/1356] Elapsed 7m 2s (remain 12m 1s) Loss: 0.0194 \n","Epoch: [3][600/1356] Elapsed 8m 26s (remain 10m 36s) Loss: 0.0214 \n","Epoch: [3][700/1356] Elapsed 9m 50s (remain 9m 12s) Loss: 0.0213 \n","Epoch: [3][800/1356] Elapsed 11m 14s (remain 7m 48s) Loss: 0.0209 \n","Epoch: [3][900/1356] Elapsed 12m 39s (remain 6m 24s) Loss: 0.0213 \n","Epoch: [3][1000/1356] Elapsed 14m 3s (remain 4m 59s) Loss: 0.0210 \n","Epoch: [3][1100/1356] Elapsed 15m 27s (remain 3m 35s) Loss: 0.0212 \n","Epoch: [3][1200/1356] Elapsed 16m 51s (remain 2m 11s) Loss: 0.0211 \n","Epoch: [3][1300/1356] Elapsed 18m 15s (remain 0m 47s) Loss: 0.0210 \n","Epoch: [3][1356/1356] Elapsed 19m 3s (remain 0m 0s) Loss: 0.0210 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 39s) Loss: 0.0003 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0479 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0547 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0558 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0575 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0210  avg_val_loss: 0.0575  time: 1242s\n","Epoch 3 - Score: 0.9014514896867838 - Threshold:0.0004 - val_loss0.0575\n","Bacthsize :16 - LearningRate :2e-05\n","========== fold: 0 result ==========\n","Score: 0.91682 - Threshold：0.05270\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1356] Elapsed 0m 1s (remain 24m 28s) Loss: 0.8290 \n","Epoch: [1][100/1356] Elapsed 1m 25s (remain 17m 41s) Loss: 0.1450 \n","Epoch: [1][200/1356] Elapsed 2m 49s (remain 16m 15s) Loss: 0.1205 \n","Epoch: [1][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.1106 \n","Epoch: [1][400/1356] Elapsed 5m 38s (remain 13m 26s) Loss: 0.1055 \n","Epoch: [1][500/1356] Elapsed 7m 2s (remain 12m 1s) Loss: 0.1011 \n","Epoch: [1][600/1356] Elapsed 8m 26s (remain 10m 37s) Loss: 0.0928 \n","Epoch: [1][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0908 \n","Epoch: [1][800/1356] Elapsed 11m 15s (remain 7m 48s) Loss: 0.0881 \n","Epoch: [1][900/1356] Elapsed 12m 39s (remain 6m 24s) Loss: 0.0839 \n","Epoch: [1][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0813 \n","Epoch: [1][1100/1356] Elapsed 15m 28s (remain 3m 35s) Loss: 0.0789 \n","Epoch: [1][1200/1356] Elapsed 16m 52s (remain 2m 11s) Loss: 0.0768 \n","Epoch: [1][1300/1356] Elapsed 18m 16s (remain 0m 47s) Loss: 0.0754 \n","Epoch: [1][1356/1356] Elapsed 19m 4s (remain 0m 0s) Loss: 0.0743 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 41s) Loss: 0.0862 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0553 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0493 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0476 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0490 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0743  avg_val_loss: 0.0490  time: 1243s\n","Epoch 1 - Score: 0.9161328765082676 - Threshold:0.0096 - val_loss0.0490\n","Epoch 1 - Save Best Score: 0.9161 Model - bestThr0.00960 - val_loss0.0490\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1356] Elapsed 0m 1s (remain 23m 49s) Loss: 0.1254 \n","Epoch: [2][100/1356] Elapsed 1m 25s (remain 17m 41s) Loss: 0.0491 \n","Epoch: [2][200/1356] Elapsed 2m 49s (remain 16m 16s) Loss: 0.0496 \n","Epoch: [2][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.0478 \n","Epoch: [2][400/1356] Elapsed 5m 38s (remain 13m 26s) Loss: 0.0452 \n","Epoch: [2][500/1356] Elapsed 7m 2s (remain 12m 2s) Loss: 0.0464 \n","Epoch: [2][600/1356] Elapsed 8m 27s (remain 10m 37s) Loss: 0.0452 \n","Epoch: [2][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0434 \n","Epoch: [2][800/1356] Elapsed 11m 15s (remain 7m 49s) Loss: 0.0440 \n","Epoch: [2][900/1356] Elapsed 12m 40s (remain 6m 24s) Loss: 0.0441 \n","Epoch: [2][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0435 \n","Epoch: [2][1100/1356] Elapsed 15m 28s (remain 3m 35s) Loss: 0.0430 \n","Epoch: [2][1200/1356] Elapsed 16m 53s (remain 2m 11s) Loss: 0.0423 \n","Epoch: [2][1300/1356] Elapsed 18m 17s (remain 0m 47s) Loss: 0.0438 \n","Epoch: [2][1356/1356] Elapsed 19m 4s (remain 0m 0s) Loss: 0.0442 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 43s) Loss: 0.1490 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0586 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0527 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0495 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0518 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0442  avg_val_loss: 0.0518  time: 1243s\n","Epoch 2 - Score: 0.9210138520483347 - Threshold:0.0042 - val_loss0.0518\n","Epoch 2 - Save Best Score: 0.9210 Model - bestThr0.00420 - val_loss0.0518\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1356] Elapsed 0m 1s (remain 24m 10s) Loss: 0.0213 \n","Epoch: [3][100/1356] Elapsed 1m 25s (remain 17m 42s) Loss: 0.0471 \n","Epoch: [3][200/1356] Elapsed 2m 49s (remain 16m 16s) Loss: 0.0470 \n","Epoch: [3][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.0433 \n","Epoch: [3][400/1356] Elapsed 5m 38s (remain 13m 26s) Loss: 0.0428 \n","Epoch: [3][500/1356] Elapsed 7m 2s (remain 12m 2s) Loss: 0.0424 \n","Epoch: [3][600/1356] Elapsed 8m 27s (remain 10m 38s) Loss: 0.0423 \n","Epoch: [3][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0392 \n","Epoch: [3][800/1356] Elapsed 11m 15s (remain 7m 49s) Loss: 0.0375 \n","Epoch: [3][900/1356] Elapsed 12m 40s (remain 6m 24s) Loss: 0.0373 \n","Epoch: [3][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0368 \n","Epoch: [3][1100/1356] Elapsed 15m 29s (remain 3m 36s) Loss: 0.0372 \n","Epoch: [3][1200/1356] Elapsed 16m 53s (remain 2m 11s) Loss: 0.0362 \n","Epoch: [3][1300/1356] Elapsed 18m 17s (remain 0m 47s) Loss: 0.0355 \n","Epoch: [3][1356/1356] Elapsed 19m 5s (remain 0m 0s) Loss: 0.0356 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 43s) Loss: 0.0544 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0430 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0345 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0346 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0354 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0356  avg_val_loss: 0.0354  time: 1244s\n","Epoch 3 - Score: 0.9355187876913562 - Threshold:0.0449 - val_loss0.0354\n","Epoch 3 - Save Best Score: 0.9355 Model - bestThr0.04490 - val_loss0.0354\n","Bacthsize :16 - LearningRate :2e-05\n","========== fold: 1 result ==========\n","Score: 0.93552 - Threshold：0.04490\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1356] Elapsed 0m 1s (remain 23m 51s) Loss: 0.4726 \n","Epoch: [1][100/1356] Elapsed 1m 25s (remain 17m 42s) Loss: 0.1267 \n","Epoch: [1][200/1356] Elapsed 2m 49s (remain 16m 16s) Loss: 0.1055 \n","Epoch: [1][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.0996 \n","Epoch: [1][400/1356] Elapsed 5m 38s (remain 13m 27s) Loss: 0.0901 \n","Epoch: [1][500/1356] Elapsed 7m 3s (remain 12m 2s) Loss: 0.0854 \n","Epoch: [1][600/1356] Elapsed 8m 27s (remain 10m 38s) Loss: 0.0827 \n","Epoch: [1][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0791 \n","Epoch: [1][800/1356] Elapsed 11m 16s (remain 7m 49s) Loss: 0.0757 \n","Epoch: [1][900/1356] Elapsed 12m 40s (remain 6m 24s) Loss: 0.0722 \n","Epoch: [1][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0703 \n","Epoch: [1][1100/1356] Elapsed 15m 29s (remain 3m 36s) Loss: 0.0682 \n","Epoch: [1][1200/1356] Elapsed 16m 53s (remain 2m 11s) Loss: 0.0671 \n","Epoch: [1][1300/1356] Elapsed 18m 18s (remain 0m 47s) Loss: 0.0660 \n","Epoch: [1][1356/1356] Elapsed 19m 5s (remain 0m 0s) Loss: 0.0658 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 42s) Loss: 0.0426 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0349 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0381 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0397 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0392 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0658  avg_val_loss: 0.0392  time: 1244s\n","Epoch 1 - Score: 0.9169363538295578 - Threshold:0.0566 - val_loss0.0392\n","Epoch 1 - Save Best Score: 0.9169 Model - bestThr0.05660 - val_loss0.0392\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1356] Elapsed 0m 1s (remain 24m 16s) Loss: 0.2234 \n","Epoch: [2][100/1356] Elapsed 1m 25s (remain 17m 43s) Loss: 0.0282 \n","Epoch: [2][200/1356] Elapsed 2m 49s (remain 16m 16s) Loss: 0.0339 \n","Epoch: [2][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.0310 \n","Epoch: [2][400/1356] Elapsed 5m 38s (remain 13m 27s) Loss: 0.0302 \n","Epoch: [2][500/1356] Elapsed 7m 2s (remain 12m 2s) Loss: 0.0309 \n","Epoch: [2][600/1356] Elapsed 8m 27s (remain 10m 38s) Loss: 0.0297 \n","Epoch: [2][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0311 \n","Epoch: [2][800/1356] Elapsed 11m 16s (remain 7m 49s) Loss: 0.0311 \n","Epoch: [2][900/1356] Elapsed 12m 40s (remain 6m 24s) Loss: 0.0318 \n","Epoch: [2][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0321 \n","Epoch: [2][1100/1356] Elapsed 15m 29s (remain 3m 36s) Loss: 0.0330 \n","Epoch: [2][1200/1356] Elapsed 16m 53s (remain 2m 11s) Loss: 0.0329 \n","Epoch: [2][1300/1356] Elapsed 18m 18s (remain 0m 47s) Loss: 0.0333 \n","Epoch: [2][1356/1356] Elapsed 19m 5s (remain 0m 0s) Loss: 0.0329 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 40s) Loss: 0.0766 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0377 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0458 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0460 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0458 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0329  avg_val_loss: 0.0458  time: 1244s\n","Epoch 2 - Score: 0.9163889730384732 - Threshold:0.0230 - val_loss0.0458\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1356] Elapsed 0m 1s (remain 23m 48s) Loss: 0.0519 \n","Epoch: [3][100/1356] Elapsed 1m 25s (remain 17m 42s) Loss: 0.0075 \n","Epoch: [3][200/1356] Elapsed 2m 49s (remain 16m 16s) Loss: 0.0129 \n","Epoch: [3][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.0137 \n","Epoch: [3][400/1356] Elapsed 5m 38s (remain 13m 27s) Loss: 0.0140 \n","Epoch: [3][500/1356] Elapsed 7m 2s (remain 12m 2s) Loss: 0.0153 \n","Epoch: [3][600/1356] Elapsed 8m 27s (remain 10m 38s) Loss: 0.0141 \n","Epoch: [3][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0169 \n","Epoch: [3][800/1356] Elapsed 11m 16s (remain 7m 49s) Loss: 0.0174 \n","Epoch: [3][900/1356] Elapsed 12m 40s (remain 6m 24s) Loss: 0.0194 \n","Epoch: [3][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0196 \n","Epoch: [3][1100/1356] Elapsed 15m 29s (remain 3m 36s) Loss: 0.0202 \n","Epoch: [3][1200/1356] Elapsed 16m 53s (remain 2m 11s) Loss: 0.0203 \n","Epoch: [3][1300/1356] Elapsed 18m 18s (remain 0m 47s) Loss: 0.0202 \n","Epoch: [3][1356/1356] Elapsed 19m 5s (remain 0m 0s) Loss: 0.0206 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 43s) Loss: 0.0099 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0324 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0387 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0401 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0393 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0206  avg_val_loss: 0.0393  time: 1244s\n","Epoch 3 - Score: 0.9187123327943555 - Threshold:0.0066 - val_loss0.0393\n","Epoch 3 - Save Best Score: 0.9187 Model - bestThr0.00660 - val_loss0.0393\n","Bacthsize :16 - LearningRate :2e-05\n","========== fold: 2 result ==========\n","Score: 0.91871 - Threshold：0.00660\n","========== fold: 3 training ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1356] Elapsed 0m 1s (remain 23m 50s) Loss: 0.7418 \n","Epoch: [1][100/1356] Elapsed 1m 25s (remain 17m 41s) Loss: 0.1428 \n","Epoch: [1][200/1356] Elapsed 2m 49s (remain 16m 16s) Loss: 0.1126 \n","Epoch: [1][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.1124 \n","Epoch: [1][400/1356] Elapsed 5m 38s (remain 13m 27s) Loss: 0.1044 \n","Epoch: [1][500/1356] Elapsed 7m 2s (remain 12m 2s) Loss: 0.0954 \n","Epoch: [1][600/1356] Elapsed 8m 27s (remain 10m 38s) Loss: 0.0892 \n","Epoch: [1][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0843 \n","Epoch: [1][800/1356] Elapsed 11m 15s (remain 7m 49s) Loss: 0.0826 \n","Epoch: [1][900/1356] Elapsed 12m 40s (remain 6m 24s) Loss: 0.0793 \n","Epoch: [1][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0760 \n","Epoch: [1][1100/1356] Elapsed 15m 29s (remain 3m 36s) Loss: 0.0743 \n","Epoch: [1][1200/1356] Elapsed 16m 53s (remain 2m 11s) Loss: 0.0717 \n","Epoch: [1][1300/1356] Elapsed 18m 17s (remain 0m 47s) Loss: 0.0694 \n","Epoch: [1][1356/1356] Elapsed 19m 4s (remain 0m 0s) Loss: 0.0684 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 44s) Loss: 0.0041 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0428 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0454 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0451 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0435 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0684  avg_val_loss: 0.0435  time: 1244s\n","Epoch 1 - Score: 0.8753353098969364 - Threshold:0.0083 - val_loss0.0435\n","Epoch 1 - Save Best Score: 0.8753 Model - bestThr0.00830 - val_loss0.0435\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1356] Elapsed 0m 1s (remain 24m 16s) Loss: 0.0502 \n","Epoch: [2][100/1356] Elapsed 1m 25s (remain 17m 41s) Loss: 0.0256 \n","Epoch: [2][200/1356] Elapsed 2m 49s (remain 16m 16s) Loss: 0.0263 \n","Epoch: [2][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.0286 \n","Epoch: [2][400/1356] Elapsed 5m 38s (remain 13m 26s) Loss: 0.0271 \n","Epoch: [2][500/1356] Elapsed 7m 2s (remain 12m 2s) Loss: 0.0295 \n","Epoch: [2][600/1356] Elapsed 8m 27s (remain 10m 37s) Loss: 0.0307 \n","Epoch: [2][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0320 \n","Epoch: [2][800/1356] Elapsed 11m 15s (remain 7m 49s) Loss: 0.0334 \n","Epoch: [2][900/1356] Elapsed 12m 40s (remain 6m 24s) Loss: 0.0326 \n","Epoch: [2][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0333 \n","Epoch: [2][1100/1356] Elapsed 15m 28s (remain 3m 35s) Loss: 0.0334 \n","Epoch: [2][1200/1356] Elapsed 16m 53s (remain 2m 11s) Loss: 0.0342 \n","Epoch: [2][1300/1356] Elapsed 18m 17s (remain 0m 47s) Loss: 0.0334 \n","Epoch: [2][1356/1356] Elapsed 19m 4s (remain 0m 0s) Loss: 0.0334 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 42s) Loss: 0.0014 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0478 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0452 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0458 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0430 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0334  avg_val_loss: 0.0430  time: 1243s\n","Epoch 2 - Score: 0.8931229532598988 - Threshold:0.0078 - val_loss0.0430\n","Epoch 2 - Save Best Score: 0.8931 Model - bestThr0.00780 - val_loss0.0430\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1356] Elapsed 0m 1s (remain 24m 16s) Loss: 0.0032 \n","Epoch: [3][100/1356] Elapsed 1m 25s (remain 17m 42s) Loss: 0.0142 \n","Epoch: [3][200/1356] Elapsed 2m 49s (remain 16m 16s) Loss: 0.0144 \n","Epoch: [3][300/1356] Elapsed 4m 14s (remain 14m 51s) Loss: 0.0169 \n","Epoch: [3][400/1356] Elapsed 5m 38s (remain 13m 26s) Loss: 0.0211 \n","Epoch: [3][500/1356] Elapsed 7m 2s (remain 12m 2s) Loss: 0.0198 \n","Epoch: [3][600/1356] Elapsed 8m 26s (remain 10m 37s) Loss: 0.0204 \n","Epoch: [3][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0208 \n","Epoch: [3][800/1356] Elapsed 11m 15s (remain 7m 48s) Loss: 0.0220 \n","Epoch: [3][900/1356] Elapsed 12m 39s (remain 6m 24s) Loss: 0.0218 \n","Epoch: [3][1000/1356] Elapsed 14m 4s (remain 5m 0s) Loss: 0.0218 \n","Epoch: [3][1100/1356] Elapsed 15m 28s (remain 3m 35s) Loss: 0.0215 \n","Epoch: [3][1200/1356] Elapsed 16m 52s (remain 2m 11s) Loss: 0.0213 \n","Epoch: [3][1300/1356] Elapsed 18m 17s (remain 0m 47s) Loss: 0.0223 \n","Epoch: [3][1356/1356] Elapsed 19m 4s (remain 0m 0s) Loss: 0.0218 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 43s) Loss: 0.0001 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0708 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0598 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0570 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0538 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0218  avg_val_loss: 0.0538  time: 1243s\n","Epoch 3 - Score: 0.8842443729903536 - Threshold:0.0002 - val_loss0.0538\n","Bacthsize :16 - LearningRate :2e-05\n","========== fold: 3 result ==========\n","Score: 0.89312 - Threshold：0.00780\n","========== fold: 4 training ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1356] Elapsed 0m 1s (remain 24m 16s) Loss: 0.4662 \n","Epoch: [1][100/1356] Elapsed 1m 25s (remain 17m 41s) Loss: 0.1226 \n","Epoch: [1][200/1356] Elapsed 2m 49s (remain 16m 15s) Loss: 0.1141 \n","Epoch: [1][300/1356] Elapsed 4m 13s (remain 14m 51s) Loss: 0.0992 \n","Epoch: [1][400/1356] Elapsed 5m 38s (remain 13m 26s) Loss: 0.0923 \n","Epoch: [1][500/1356] Elapsed 7m 2s (remain 12m 2s) Loss: 0.0886 \n","Epoch: [1][600/1356] Elapsed 8m 26s (remain 10m 37s) Loss: 0.0868 \n","Epoch: [1][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0831 \n","Epoch: [1][800/1356] Elapsed 11m 15s (remain 7m 48s) Loss: 0.0804 \n","Epoch: [1][900/1356] Elapsed 12m 39s (remain 6m 24s) Loss: 0.0768 \n","Epoch: [1][1000/1356] Elapsed 14m 3s (remain 5m 0s) Loss: 0.0727 \n","Epoch: [1][1100/1356] Elapsed 15m 28s (remain 3m 35s) Loss: 0.0695 \n","Epoch: [1][1200/1356] Elapsed 16m 52s (remain 2m 11s) Loss: 0.0667 \n","Epoch: [1][1300/1356] Elapsed 18m 16s (remain 0m 47s) Loss: 0.0659 \n","Epoch: [1][1356/1356] Elapsed 19m 3s (remain 0m 0s) Loss: 0.0647 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 46s) Loss: 0.0024 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0380 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0406 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0418 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0436 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0647  avg_val_loss: 0.0436  time: 1243s\n","Epoch 1 - Score: 0.9057437407952871 - Threshold:0.0073 - val_loss0.0436\n","Epoch 1 - Save Best Score: 0.9057 Model - bestThr0.00730 - val_loss0.0436\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/1356] Elapsed 0m 1s (remain 24m 29s) Loss: 0.0016 \n","Epoch: [2][100/1356] Elapsed 1m 25s (remain 17m 41s) Loss: 0.0370 \n","Epoch: [2][200/1356] Elapsed 2m 49s (remain 16m 15s) Loss: 0.0294 \n","Epoch: [2][300/1356] Elapsed 4m 13s (remain 14m 50s) Loss: 0.0306 \n","Epoch: [2][400/1356] Elapsed 5m 38s (remain 13m 26s) Loss: 0.0326 \n","Epoch: [2][500/1356] Elapsed 7m 2s (remain 12m 1s) Loss: 0.0335 \n","Epoch: [2][600/1356] Elapsed 8m 26s (remain 10m 37s) Loss: 0.0344 \n","Epoch: [2][700/1356] Elapsed 9m 51s (remain 9m 13s) Loss: 0.0362 \n","Epoch: [2][800/1356] Elapsed 11m 15s (remain 7m 48s) Loss: 0.0345 \n","Epoch: [2][900/1356] Elapsed 12m 39s (remain 6m 24s) Loss: 0.0340 \n","Epoch: [2][1000/1356] Elapsed 14m 3s (remain 5m 0s) Loss: 0.0339 \n","Epoch: [2][1100/1356] Elapsed 15m 28s (remain 3m 35s) Loss: 0.0341 \n","Epoch: [2][1200/1356] Elapsed 16m 52s (remain 2m 11s) Loss: 0.0335 \n","Epoch: [2][1300/1356] Elapsed 18m 16s (remain 0m 47s) Loss: 0.0336 \n","Epoch: [2][1356/1356] Elapsed 19m 3s (remain 0m 0s) Loss: 0.0334 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 44s) Loss: 0.0006 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0366 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0406 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0407 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0422 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0334  avg_val_loss: 0.0422  time: 1242s\n","Epoch 2 - Score: 0.9101760668457177 - Threshold:0.0037 - val_loss0.0422\n","Epoch 2 - Save Best Score: 0.9102 Model - bestThr0.00370 - val_loss0.0422\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/1356] Elapsed 0m 1s (remain 24m 10s) Loss: 0.1626 \n","Epoch: [3][100/1356] Elapsed 1m 25s (remain 17m 41s) Loss: 0.0245 \n","Epoch: [3][200/1356] Elapsed 2m 49s (remain 16m 15s) Loss: 0.0204 \n","Epoch: [3][300/1356] Elapsed 4m 13s (remain 14m 50s) Loss: 0.0216 \n","Epoch: [3][400/1356] Elapsed 5m 38s (remain 13m 26s) Loss: 0.0245 \n","Epoch: [3][500/1356] Elapsed 7m 2s (remain 12m 1s) Loss: 0.0240 \n","Epoch: [3][600/1356] Elapsed 8m 26s (remain 10m 37s) Loss: 0.0245 \n","Epoch: [3][700/1356] Elapsed 9m 50s (remain 9m 12s) Loss: 0.0236 \n","Epoch: [3][800/1356] Elapsed 11m 15s (remain 7m 48s) Loss: 0.0223 \n","Epoch: [3][900/1356] Elapsed 12m 39s (remain 6m 24s) Loss: 0.0223 \n","Epoch: [3][1000/1356] Elapsed 14m 3s (remain 5m 0s) Loss: 0.0222 \n","Epoch: [3][1100/1356] Elapsed 15m 28s (remain 3m 35s) Loss: 0.0219 \n","Epoch: [3][1200/1356] Elapsed 16m 52s (remain 2m 11s) Loss: 0.0217 \n","Epoch: [3][1300/1356] Elapsed 18m 16s (remain 0m 47s) Loss: 0.0217 \n","Epoch: [3][1356/1356] Elapsed 19m 3s (remain 0m 0s) Loss: 0.0215 \n","EVAL: [0/339] Elapsed 0m 0s (remain 2m 46s) Loss: 0.0002 \n","EVAL: [100/339] Elapsed 0m 28s (remain 1m 8s) Loss: 0.0481 \n","EVAL: [200/339] Elapsed 0m 57s (remain 0m 39s) Loss: 0.0454 \n","EVAL: [300/339] Elapsed 1m 25s (remain 0m 11s) Loss: 0.0501 \n","EVAL: [339/339] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0505 \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0215  avg_val_loss: 0.0505  time: 1242s\n","Epoch 3 - Score: 0.9183980728696175 - Threshold:0.0014 - val_loss0.0505\n","Epoch 3 - Save Best Score: 0.9184 Model - bestThr0.00140 - val_loss0.0505\n","Bacthsize :16 - LearningRate :2e-05\n","========== fold: 4 result ==========\n","Score: 0.91840 - Threshold：0.00140\n","========== CV ==========\n","Score: 0.89610 - Threshold：0.02268\n","========== model 0 inference ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72753330ede145e8abb2ecdd490e69e2","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2553 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["========== model 1 inference ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6434bfb05d5447cd8579ad9a04018532","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2553 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["========== model 2 inference ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9146bd377574a118845059ba6654671","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2553 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["========== model 3 inference ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3b35b9862a9431f9a282f08156a7f70","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2553 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["========== model 4 inference ==========\n","Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59ff03d97da843b6bc9f3dfe9a7f7da4","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2553 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["==========CONPLETE==========\n"]}]},{"cell_type":"markdown","metadata":{"id":"PkjhOs_a7Two"},"source":["## モデルのトレーニングのみ実行"]},{"cell_type":"code","metadata":{"id":"tlg4XhI862HQ","executionInfo":{"status":"ok","timestamp":1633946659703,"user_tz":-540,"elapsed":758,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["# if __name__ == \"__main__\":\n","#     trainning()"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C2zwj1657cdl"},"source":["## testデータの予測のみ"]},{"cell_type":"code","metadata":{"id":"aGzA2OoF6150","executionInfo":{"status":"ok","timestamp":1633946662650,"user_tz":-540,"elapsed":2,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["# # 学習済みモデルの予測のみ行う場合\n","# if __name__ == \"__main__\":\n","#     predictions_sigmoid = inference_submit()\n","\n","# #確率をファイルとして残す\n","# pd.DataFrame(predictions_sigmoid, columns=['proba']).to_csv(Proba_DIR+'proba.csv')"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sv-xqpJklvea"},"source":["# 提出前準備"]},{"cell_type":"code","metadata":{"id":"N4Z5JiGynXnz","executionInfo":{"status":"ok","timestamp":1633946663674,"user_tz":-540,"elapsed":1,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["# ランタイムが切れた時用に読み込む\n","# predictions = pd.read_csv(Proba_DIR+'proba.csv').drop('Unnamed: 0', axis=1)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKuiglsuANtE","executionInfo":{"status":"ok","timestamp":1633946683854,"user_tz":-540,"elapsed":559,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}}},"source":["  # submission、予測とシグモイド関数を得て、閾値を手動で調整できるようにする\n","  Best_Threshold = 0.02268\n","  predictions = np.where(predictions < Best_Threshold, 0, 1)\n","  sub[\"judgement\"] = predictions\n","  sub.to_csv(OUTPUT_DIR + \"submission.csv\", index=False, header=False)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sR932FUHl4a6"},"source":["# CVのベストな閾値探索\n","こちらの閾値と自動算出の閾値どちらがいいかはわかりませんが、汎化性能が高いのはたぶん自動算出"]},{"cell_type":"code","metadata":{"id":"N4iLvaHKc9SP","colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"status":"ok","timestamp":1633946696738,"user_tz":-540,"elapsed":9978,"user":{"displayName":"Tsukasa Saito","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01961766842830427914"}},"outputId":"d5a0b301-f127-49c6-9c5d-ff2ad2cf6216"},"source":["DF = pd.read_csv(OUTPUT_DIR+\"oof_df.csv\")\n","#ベストな閾値を探す\n","Threshold_list = []\n","f_beta_score_list = []\n","for i in range(1000):\n","    Threshold = i*0.0001\n","    predictions = np.where(DF[\"preds\"] < Threshold, 0, 1)\n","    Threshold_list.append(Threshold)\n","    f_beta_score_list.append(fbeta_score(DF[\"judgement\"], predictions, beta=7.0))\n","sns.set()\n","plt.plot(Threshold_list, f_beta_score_list)\n","for i,j in zip(Threshold_list, f_beta_score_list):\n","    if j == max(f_beta_score_list):\n","        print('Best Threshold :', i)\n","        print('Best F-Beta-Score :', j)\n","        break"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Threshold : 0.0083\n","Best F-Beta-Score : 0.8987532944416475\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{}}]}]}